{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is normal SNN network without stashing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import snntorch as snn\n",
    "from snntorch import spikeplot as splt\n",
    "from snntorch import spikegen\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import itertools\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "batch_size = 64\n",
    "epochs = 5\n",
    "beta = 0.95\n",
    "# The beta defined here = (1 - delta(t)/Tau)\n",
    "# Here delta(t) is the clk period\n",
    "# Tau = Time constant = RC\n",
    "# This is the approximation of beta = exp(-delta(t)/Tau)\n",
    "num_steps = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Perform learning over cuda\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "            transforms.Resize((28, 28)),\n",
    "            transforms.Grayscale(),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0,), (1,))])\n",
    "\n",
    "mnist_train = datasets.MNIST(\"/home/neel/Sem_8/RnD/RnD_rough/data\", train=True, download=True, transform=transform)\n",
    "mnist_test = datasets.MNIST(\"/home/neel/Sem_8/RnD/RnD_rough/data\", train=False, download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the training and test data\n",
    "train_loader = DataLoader(mnist_train, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "test_loader = DataLoader(mnist_test, batch_size=batch_size, shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here we are creating a single hidden layer NN, with 150 nodes\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, num_hidden_layer = 150):\n",
    "        super().__init__()\n",
    "\n",
    "        # Initialize layers\n",
    "        self.input_layer = nn.ModuleList([nn.Linear(in_features=784, out_features=1) for i in range(num_hidden_layer)])\n",
    "        self.lif1 = snn.Leaky(beta=beta)\n",
    "        self.output_layer = nn.Linear(in_features=num_hidden_layer, out_features=10)\n",
    "        self.lif2 = snn.Leaky(beta=beta)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        # Initialize hidden states at t=0\n",
    "        mem1 = self.lif1.init_leaky()\n",
    "        mem2 = self.lif2.init_leaky()\n",
    "\n",
    "        # Record the final layer\n",
    "        spk2_rec = []\n",
    "        mem2_rec = []\n",
    "\n",
    "        for step in range(num_steps):\n",
    "            cur1 = [self.input_layer[i](x) for i in range(num_hidden_layer)]\n",
    "            cur1 = torch.hstack(cur1)\n",
    "            spk1, mem1 = self.lif1(cur1, mem1)\n",
    "            cur2 = self.output_layer(spk1)\n",
    "            spk2, mem2 = self.lif2(cur2, mem2)\n",
    "            spk2_rec.append(spk2)\n",
    "            mem2_rec.append(mem2)\n",
    "\n",
    "        return torch.stack(spk2_rec, dim=0), torch.stack(mem2_rec, dim=0)\n",
    "\n",
    "# Load the network onto CUDA if available\n",
    "num_hidden_layer = 150\n",
    "model = Net(num_hidden_layer=num_hidden_layer).to(device)\n",
    "next(model.parameters()).is_cuda\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(model.parameters()).is_cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy():\n",
    "    with torch.no_grad():\n",
    "        n_correct = 0\n",
    "        n_samples = 0\n",
    "        for images, label in test_loader:\n",
    "            images = images.reshape(-1, 28*28).to(device)\n",
    "            label = label.to(device)\n",
    "\n",
    "            # Test set forward pass\n",
    "            test_spk, test_mem = model(images.view(batch_size, -1))\n",
    "            n_samples += label.size(0)\n",
    "            _, idx = test_spk.sum(dim=0).max(1)\n",
    "            n_correct+= (label == idx).sum().item()\n",
    "            return(n_correct/n_samples * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[20, 112, 116, 63, 24, 135, 94, 119, 81, 72, 97, 106, 5, 113, 28]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generating non duplicate random nodes to be stashed out of hidden layer per epoch \n",
    "import random\n",
    "stashed = random.sample(range(num_hidden_layer), 15)\n",
    "stashed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Step[100/937], Loss: 18.5441\n",
      "-------------------------\n",
      "Epoch [1/5], Step[200/937], Loss: 21.3070\n",
      "-------------------------\n",
      "Epoch [1/5], Step[300/937], Loss: 19.4786\n",
      "-------------------------\n",
      "Accuracy is 89.0625\n",
      "Node stashed 20\n",
      "-------------------------\n",
      "Epoch [1/5], Step[400/937], Loss: 11.3613\n",
      "-------------------------\n",
      "Epoch [1/5], Step[500/937], Loss: 12.1799\n",
      "-------------------------\n",
      "Epoch [1/5], Step[600/937], Loss: 15.0556\n",
      "-------------------------\n",
      "Accuracy is 81.25\n",
      "Node stashed 112\n",
      "-------------------------\n",
      "Epoch [1/5], Step[700/937], Loss: 16.1833\n",
      "-------------------------\n",
      "Epoch [1/5], Step[800/937], Loss: 17.4335\n",
      "-------------------------\n",
      "Epoch [1/5], Step[900/937], Loss: 9.9518\n",
      "-------------------------\n",
      "Accuracy is 85.9375\n",
      "Node stashed 116\n",
      "-------------------------\n",
      "Epoch [2/5], Step[100/937], Loss: 11.9394\n",
      "-------------------------\n",
      "Epoch [2/5], Step[200/937], Loss: 13.3232\n",
      "-------------------------\n",
      "Epoch [2/5], Step[300/937], Loss: 9.5651\n",
      "-------------------------\n",
      "Accuracy is 89.0625\n",
      "Node stashed 63\n",
      "-------------------------\n",
      "Epoch [2/5], Step[400/937], Loss: 16.4155\n",
      "-------------------------\n",
      "Epoch [2/5], Step[500/937], Loss: 7.8603\n",
      "-------------------------\n",
      "Epoch [2/5], Step[600/937], Loss: 9.6945\n",
      "-------------------------\n",
      "Accuracy is 84.375\n",
      "Node stashed 24\n",
      "-------------------------\n",
      "Epoch [2/5], Step[700/937], Loss: 12.8463\n",
      "-------------------------\n",
      "Epoch [2/5], Step[800/937], Loss: 8.8350\n",
      "-------------------------\n",
      "Epoch [2/5], Step[900/937], Loss: 7.8859\n",
      "-------------------------\n",
      "Accuracy is 84.375\n",
      "Node stashed 135\n",
      "-------------------------\n",
      "Epoch [3/5], Step[100/937], Loss: 4.6479\n",
      "-------------------------\n",
      "Epoch [3/5], Step[200/937], Loss: 5.9711\n",
      "-------------------------\n",
      "Epoch [3/5], Step[300/937], Loss: 7.4996\n",
      "-------------------------\n",
      "Accuracy is 89.0625\n",
      "Node stashed 94\n",
      "-------------------------\n",
      "Epoch [3/5], Step[400/937], Loss: 7.0995\n",
      "-------------------------\n",
      "Epoch [3/5], Step[500/937], Loss: 11.9109\n",
      "-------------------------\n",
      "Epoch [3/5], Step[600/937], Loss: 9.8251\n",
      "-------------------------\n",
      "Accuracy is 84.375\n",
      "Node stashed 119\n",
      "-------------------------\n",
      "Epoch [3/5], Step[700/937], Loss: 12.1451\n",
      "-------------------------\n",
      "Epoch [3/5], Step[800/937], Loss: 5.1340\n",
      "-------------------------\n",
      "Epoch [3/5], Step[900/937], Loss: 6.6855\n",
      "-------------------------\n",
      "Accuracy is 87.5\n",
      "Node stashed 81\n",
      "-------------------------\n",
      "Epoch [4/5], Step[100/937], Loss: 7.4999\n",
      "-------------------------\n",
      "Epoch [4/5], Step[200/937], Loss: 6.1751\n",
      "-------------------------\n",
      "Epoch [4/5], Step[300/937], Loss: 12.9647\n",
      "-------------------------\n",
      "Accuracy is 92.1875\n",
      "Node stashed 72\n",
      "-------------------------\n",
      "Epoch [4/5], Step[400/937], Loss: 8.8204\n",
      "-------------------------\n",
      "Epoch [4/5], Step[500/937], Loss: 7.4537\n",
      "-------------------------\n",
      "Epoch [4/5], Step[600/937], Loss: 9.8603\n",
      "-------------------------\n",
      "Accuracy is 92.1875\n",
      "Node stashed 97\n",
      "-------------------------\n",
      "Epoch [4/5], Step[700/937], Loss: 10.1305\n",
      "-------------------------\n",
      "Epoch [4/5], Step[800/937], Loss: 8.5731\n",
      "-------------------------\n",
      "Epoch [4/5], Step[900/937], Loss: 6.9014\n",
      "-------------------------\n",
      "Accuracy is 95.3125\n",
      "Node stashed 106\n",
      "-------------------------\n",
      "Epoch [5/5], Step[100/937], Loss: 7.6661\n",
      "-------------------------\n",
      "Epoch [5/5], Step[200/937], Loss: 6.2965\n",
      "-------------------------\n",
      "Epoch [5/5], Step[300/937], Loss: 6.5432\n",
      "-------------------------\n",
      "Accuracy is 92.1875\n",
      "Node stashed 5\n",
      "-------------------------\n",
      "Epoch [5/5], Step[400/937], Loss: 5.1183\n",
      "-------------------------\n",
      "Epoch [5/5], Step[500/937], Loss: 5.8783\n",
      "-------------------------\n",
      "Epoch [5/5], Step[600/937], Loss: 6.8513\n",
      "-------------------------\n",
      "Accuracy is 89.0625\n",
      "Node stashed 113\n",
      "-------------------------\n",
      "Epoch [5/5], Step[700/937], Loss: 5.6534\n",
      "-------------------------\n",
      "Epoch [5/5], Step[800/937], Loss: 8.4621\n",
      "-------------------------\n",
      "Epoch [5/5], Step[900/937], Loss: 4.3859\n",
      "-------------------------\n",
      "Accuracy is 95.3125\n",
      "Node stashed 28\n",
      "-------------------------\n"
     ]
    }
   ],
   "source": [
    "j=0\n",
    "n_total_steps = len(train_loader)\n",
    "for epoch_iter in range(epochs):\n",
    "    for i,(data, target) in enumerate(train_loader):\n",
    "        x = data.to(device)\n",
    "        y = target.to(device)\n",
    "        spk_rec, mem_rec = model(x.view(batch_size, -1))\n",
    "        loss_val = torch.zeros((1),device=device)\n",
    "        for step in range(num_steps):\n",
    "            loss_val += loss(mem_rec[step], y)\n",
    "        optimizer.zero_grad()\n",
    "        loss_val.backward()\n",
    "        optimizer.step()\n",
    "        if (i+1) % 100 == 0:\n",
    "             print (f'Epoch [{epoch_iter+1}/{epochs}], Step[{i+1}/{n_total_steps}], Loss: {loss_val.item():.4f}')\n",
    "             print(\"-------------------------\")\n",
    "        \n",
    "        if (i+1) % 300 == 0:\n",
    "            print(\"Accuracy is\", accuracy())\n",
    "            for params in model.input_layer[stashed[j]].parameters():\n",
    "                params.requires_grad = False\n",
    "            print(\"Node stashed\", stashed[j])\n",
    "            print(\"-------------------------\")\n",
    "            j+=1\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assertion to see if our nodes have really been stashed even after the training is over\n",
    "univ = [i for i in range(num_hidden_layer)]\n",
    "not_stashed = [i for i in univ if i not in stashed]\n",
    "\n",
    "for i in stashed:\n",
    "    for j in model.input_layer[i].parameters():\n",
    "        assert j.requires_grad == False\n",
    "\n",
    "for i in not_stashed:\n",
    "    for j in model.input_layer[i].parameters():\n",
    "        assert j.requires_grad == True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "95.3125"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Creating computational graph to see, whether all the neurons are contributing or not\n",
    "# batch = next(iter(train_loader))\n",
    "# yhat = net(batch[0].reshape(-1,28*28).to(device)) # Give dummy batch to forward().\n",
    "\n",
    "# from torchviz import make_dot\n",
    "\n",
    "# make_dot(yhat, params=dict(list(net.named_parameters()))).render(\"trial_1\", format=\"png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
