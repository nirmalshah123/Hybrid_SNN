{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is normal SNN network with Stashing Randomly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import snntorch as snn\n",
    "from snntorch import spikeplot as splt\n",
    "from snntorch import spikegen\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import itertools\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "batch_size = 128\n",
    "epochs = 3\n",
    "beta = 0.95\n",
    "# The beta defined here = (1 - delta(t)/Tau)\n",
    "# Here delta(t) is the clk period\n",
    "# Tau = Time constant = RC\n",
    "# This is the approximation of beta = exp(-delta(t)/Tau)\n",
    "num_steps = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Perform learning over cuda\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "            transforms.Resize((28, 28)),\n",
    "            transforms.Grayscale(),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0,), (1,))])\n",
    "\n",
    "mnist_train = datasets.MNIST(\"./../data\", train=True, download=True, transform=transform)\n",
    "mnist_test = datasets.MNIST(\"./../data\", train=False, download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the training and test data\n",
    "train_loader = DataLoader(mnist_train, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "test_loader = DataLoader(mnist_test, batch_size=batch_size, shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here we are creating a single hidden layer NN, with 150 nodes\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, num_hidden_layer = 150):\n",
    "        super().__init__()\n",
    "\n",
    "        # Initialize layers\n",
    "        self.input_layer = nn.ModuleList([nn.Linear(in_features=784, out_features=1) for i in range(num_hidden_layer)])\n",
    "        self.lif1 = snn.Leaky(beta=beta)\n",
    "        self.output_layer = nn.Linear(in_features=num_hidden_layer, out_features=10)\n",
    "        self.lif2 = snn.Leaky(beta=beta)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        # Initialize hidden states at t=0\n",
    "        mem1 = self.lif1.init_leaky()\n",
    "        mem2 = self.lif2.init_leaky()\n",
    "\n",
    "        # Record the final layer\n",
    "        spk2_rec = []\n",
    "        mem2_rec = []\n",
    "\n",
    "        for step in range(num_steps):\n",
    "            cur1 = [self.input_layer[i](x) for i in range(num_hidden_layer)]\n",
    "            cur1 = torch.hstack(cur1)\n",
    "            spk1, mem1 = self.lif1(cur1, mem1)\n",
    "            cur2 = self.output_layer(spk1)\n",
    "            spk2, mem2 = self.lif2(cur2, mem2)\n",
    "            spk2_rec.append(spk2)\n",
    "            mem2_rec.append(mem2)\n",
    "\n",
    "        return torch.stack(spk2_rec, dim=0), torch.stack(mem2_rec, dim=0)\n",
    "\n",
    "# Load the network onto CUDA if available\n",
    "num_hidden_layer = 150\n",
    "model = Net(num_hidden_layer=num_hidden_layer).to(device)\n",
    "next(model.parameters()).is_cuda\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(model.parameters()).is_cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy():\n",
    "    with torch.no_grad():\n",
    "        n_correct = 0\n",
    "        n_samples = 0\n",
    "        for images, label in test_loader:\n",
    "            images = images.reshape(-1, 28*28).to(device)\n",
    "            label = label.to(device)\n",
    "\n",
    "            # Test set forward pass\n",
    "            test_spk, test_mem = model(images.view(batch_size, -1))\n",
    "            n_samples += label.size(0)\n",
    "            _, idx = test_spk.sum(dim=0).max(1)\n",
    "            n_correct+= (label == idx).sum().item()\n",
    "            return(n_correct/n_samples * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[38, 68, 1, 148, 101, 4]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generating non duplicate random nodes to be stashed out of hidden layer per epoch \n",
    "import random\n",
    "stashed = random.sample(range(num_hidden_layer), 6)\n",
    "stashed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/3], Step[100/468], Loss: 22.0693\n",
      "-------------------------\n",
      "Epoch [1/3], Step[200/468], Loss: 19.1155\n",
      "-------------------------\n",
      "Accuracy is 82.8125\n",
      "Node stashed 38\n",
      "-------------------------\n",
      "Epoch [1/3], Step[300/468], Loss: 18.0457\n",
      "-------------------------\n",
      "Epoch [1/3], Step[400/468], Loss: 16.9595\n",
      "-------------------------\n",
      "Accuracy is 83.59375\n",
      "Node stashed 68\n",
      "-------------------------\n",
      "Epoch [2/3], Step[100/468], Loss: 12.3625\n",
      "-------------------------\n",
      "Epoch [2/3], Step[200/468], Loss: 9.4228\n",
      "-------------------------\n",
      "Accuracy is 88.28125\n",
      "Node stashed 1\n",
      "-------------------------\n",
      "Epoch [2/3], Step[300/468], Loss: 9.8779\n",
      "-------------------------\n",
      "Epoch [2/3], Step[400/468], Loss: 15.9770\n",
      "-------------------------\n",
      "Accuracy is 92.96875\n",
      "Node stashed 148\n",
      "-------------------------\n",
      "Epoch [3/3], Step[100/468], Loss: 11.9606\n",
      "-------------------------\n",
      "Epoch [3/3], Step[200/468], Loss: 6.9147\n",
      "-------------------------\n",
      "Accuracy is 90.625\n",
      "Node stashed 101\n",
      "-------------------------\n",
      "Epoch [3/3], Step[300/468], Loss: 15.9392\n",
      "-------------------------\n",
      "Epoch [3/3], Step[400/468], Loss: 11.8134\n",
      "-------------------------\n",
      "Accuracy is 93.75\n",
      "Node stashed 4\n",
      "-------------------------\n",
      "CPU times: user 10min 20s, sys: 346 ms, total: 10min 20s\n",
      "Wall time: 10min 20s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "j=0\n",
    "n_total_steps = len(train_loader)\n",
    "for epoch_iter in range(epochs):\n",
    "    for i,(data, target) in enumerate(train_loader):\n",
    "        x = data.to(device)\n",
    "        y = target.to(device)\n",
    "        spk_rec, mem_rec = model(x.view(batch_size, -1))\n",
    "        loss_val = torch.zeros((1),device=device)\n",
    "        for step in range(num_steps):\n",
    "            loss_val += loss(mem_rec[step], y)\n",
    "        optimizer.zero_grad()\n",
    "        loss_val.backward()\n",
    "        optimizer.step()\n",
    "        if (i+1) % 100 == 0:\n",
    "             print (f'Epoch [{epoch_iter+1}/{epochs}], Step[{i+1}/{n_total_steps}], Loss: {loss_val.item():.4f}')\n",
    "             print(\"-------------------------\")\n",
    "        \n",
    "        if (i+1) % 200 == 0:\n",
    "            print(\"Accuracy is\", accuracy())\n",
    "            for params in model.input_layer[stashed[j]].parameters():\n",
    "                params.requires_grad = False\n",
    "            print(\"Node stashed\", stashed[j])\n",
    "            print(\"-------------------------\")\n",
    "            j+=1\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assertion to see if our nodes have really been stashed even after the training is over\n",
    "univ = [i for i in range(num_hidden_layer)]\n",
    "not_stashed = [i for i in univ if i not in stashed]\n",
    "\n",
    "for i in stashed:\n",
    "    for j in model.input_layer[i].parameters():\n",
    "        assert j.requires_grad == False\n",
    "\n",
    "for i in not_stashed:\n",
    "    for j in model.input_layer[i].parameters():\n",
    "        assert j.requires_grad == True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "92.96875"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model,'SNN_with_stashing_randomly.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Creating computational graph to see, whether all the neurons are contributing or not\n",
    "# batch = next(iter(train_loader))\n",
    "# yhat = net(batch[0].reshape(-1,28*28).to(device)) # Give dummy batch to forward().\n",
    "\n",
    "# from torchviz import make_dot\n",
    "\n",
    "# make_dot(yhat, params=dict(list(net.named_parameters()))).render(\"trial_1\", format=\"png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
